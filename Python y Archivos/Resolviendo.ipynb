{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Importando pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                Cabiando los archivos a .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('precios_semana_20200503.json') # Leyendo el archivo json\n",
    "df.to_csv('precios_semana_20200503.csv', index= None, sep = ',') # Convirtiendo en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('precios_semana_20200518.txt', sep = '|') # Leyendo el archivo txt\n",
    "df2.to_csv ('precios_semana_20200518.csv', index = None, sep = ',') # Convirtiendo en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_excel('precios_semanas_20200419_20200426.xlsx', sheet_name = None) # Leyendo el archivo excel\n",
    "df3 = pd.concat(df3, ignore_index = True) # Concatenando los dos excel\n",
    "df3.to_csv('precios_semanas_20200419_20200426.csv', sep = ',', index = None, header = True) # Convirtiendo en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_parquet('producto.parquet') # Leyendo el archivo parquet\n",
    "df4.to_csv('producto.csv', index = None) # Convirtiendo en csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                    Limpiando los archivos antes de importarlos a MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso que se toma en el primer DF se toma en todos los DFs por si presentan los mismos errores, siendo este primer DF el que abarca todas las correcciones de errores vistos en todos los archivos precios_semana.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0) # Esta función agrega el valor de 0 a los valores NaN.\n",
    "df['producto_id'] = df['producto_id'].astype('string').str.rstrip('.0') # Cambio de tipo de dato en la columna 'producto_id' y eliminamos el .0 que es una imperfección.\n",
    "df['producto_id'] = df['producto_id'].str.zfill(13) # Se agregan 0 al inicio de 'producto_id' hasta que los dígitos lleguen a 13 y coincidan con los id reales. \n",
    "df['sucursal_id'] = df['sucursal_id'].astype('string').str.replace('/','-') # Se cambia la barra '/' por un guión '-'.\n",
    "df['sucursal_id'] = df['sucursal_id'].str.rstrip('00:00:00') # Se elimina '00:00:00' por imperfecciones en los datos.\n",
    "df.to_csv('precios_semana_20200503.csv', index = None) # Se guarda la modificación del .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.fillna(0) # Esta función agrega el valor de 0 a los valores NaN.\n",
    "df2['producto_id'] = df2['producto_id'].astype('string').str.rstrip('.0') # Cambio de tipo de dato en la columna 'producto_id' y eliminamos el .0 que es una imperfección.\n",
    "df2['producto_id'] = df2['producto_id'].str.zfill(13) # Se agregan 0 al inicio de 'producto_id' hasta que los dígitos lleguen a 13 y coincidan con los id reales. \n",
    "df2['sucursal_id'] = df2['sucursal_id'].astype('string').str.replace('/','-') # Se cambia la barra '/' por un guión '-'.\n",
    "df2['sucursal_id'] = df2['sucursal_id'].str.rstrip('00:00:00') # Se elimina '00:00:00' por imperfecciones en los datos.\n",
    "df2.to_csv('precios_semana_20200518.csv', index = None) # Se guarda la modificación del .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.fillna(0) # Esta función agrega el valor de 0 a los valores NaN.\n",
    "df3 = df3.reindex(columns = ['precio', 'producto_id', 'sucursal_id'])\n",
    "df3['producto_id'] = df3['producto_id'].astype('string').str.rstrip('.0') # Cambio de tipo de dato en la columna 'producto_id' y eliminamos el .0 que es una imperfección.\n",
    "df3['producto_id'] = df3['producto_id'].str.zfill(13) # Se agregan 0 al inicio de 'producto_id' hasta que los dígitos lleguen a 13 y coincidan con los id reales. \n",
    "df3['sucursal_id'] = df3['sucursal_id'].astype('string').str.replace('/','-') # Se cambia la barra '/' por un guión '-'.\n",
    "df3['sucursal_id'] = df3['sucursal_id'].str.rstrip('00:00:00') # Se elimina '00:00:00' por imperfecciones en los datos.\n",
    "df3.to_csv('precios_semanas_20200419_20200426.csv', index = None) # Se guarda la modificación del .csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este DF tiene una corrección especial ya que era el único que contenia este error, luego se le agregan las correcciones de los otros DFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv('precios_semana_20200413.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['precio'] = df5['precio'].astype('string').str.replace(',', '.') # Se cambia la coma ',' por un punto '.' en la columna 'precio'\n",
    "df5 = df5.fillna(0) # Esta función agrega el valor de 0 a los valores NaN.\n",
    "df5['producto_id'] = df5['producto_id'].astype('string').str.rstrip('.0') # Cambio de tipo de dato en la columna 'producto_id' y eliminamos el .0 que es una imperfección.\n",
    "df5['producto_id'] = df5['producto_id'].str.zfill(13) # Se agregan 0 al inicio de 'producto_id' hasta que los dígitos lleguen a 13 y coincidan con los id reales. \n",
    "df5['sucursal_id'] = df5['sucursal_id'].astype('string').str.replace('/','-') # Se cambia la barra '/' por un guión '-'.\n",
    "df5['sucursal_id'] = df5['sucursal_id'].str.rstrip('00:00:00') # Se elimina '00:00:00' por imperfecciones en los datos.\n",
    "df5.to_csv('precios_semana_20200413.csv', index = None) # Se guarda la modificación del .csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                               Importando un archivo a MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine # Importamos create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexion = 'mysql+pymysql://root:42591905mago@localhost:3306/proyecto_individual' # Creamos la conección entre MySQL y Python\n",
    "conexion2 = create_engine(conexion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importando(archivo, nombre):  # Función que importa el archivo en MySQL\n",
    "    \n",
    "    \n",
    "    archivo.to_sql(name = nombre, con = conexion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "importando(df3, 'precios_semanas_20200419_20200426') # Llamando a la función y pasandole el archivo con el nombre que tendrá la tabla en MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                        Uniendo todas los archivos precios_semanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental(): # Función que junta todos los precios_semana\n",
    "\n",
    "    todas_semanas = pd.concat([df, df2, df3, df5]) # Juntando todos los precios_semana\n",
    "\n",
    "    todas_semanas.to_csv('todas_semanas') # Creando un .csv llamado 'todas_semanas' con todos los precios_semana\n",
    "\n",
    "    importando(todas_semanas,'todas_semanas') # Usando la función para enviar archivos a MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "incremental() # Llamando a la función incremental"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e7af5626c7e654314ce176c299bd4d61dd6a36e86a9674195997ac339225326"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
